{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb79f99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.2015\n",
      "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.1131\n",
      "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 2.0102\n",
      "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9186\n",
      "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.8741\n",
      "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.7558\n",
      "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.8028\n",
      "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.6453\n",
      "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.5614\n",
      "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.5545\n",
      "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.5214\n",
      "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.5204\n",
      "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.4378\n",
      "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3474\n",
      "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3228\n",
      "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.2798\n",
      "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.2879\n",
      "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2404\n",
      "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.1071\n",
      "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.2528\n",
      "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.1844\n",
      "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.2232\n",
      "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.1260\n",
      "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.0502\n",
      "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.1326\n",
      "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.1227\n",
      "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 1.1408\n",
      "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.0441\n",
      "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 1.0571\n",
      "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 1.0662\n",
      "Accuracy of the model on the 10000 test images:  82 %\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms \n",
    "from torch.autograd import Variable \n",
    "\n",
    "# MNIST Dataset (Images and Labels) \n",
    "train_dataset = dsets.MNIST(root ='/files/', \n",
    "\t\t\t\t\t\t\ttrain = True, \n",
    "\t\t\t\t\t\t\ttransform = transforms.ToTensor(), \n",
    "\t\t\t\t\t\t\tdownload = True) \n",
    "batch_size = 100\n",
    "test_dataset = dsets.MNIST(root ='/files/', \n",
    "\t\t\t\t\t\ttrain = False, \n",
    "\t\t\t\t\t\ttransform = transforms.ToTensor()) \n",
    "\n",
    "# Dataset Loader (Input Pipeline) \n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size, \n",
    "\t\t\t\t\t\t\t\t\t\tshuffle = True) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size, \n",
    "\t\t\t\t\t\t\t\t\t\tshuffle = False) \n",
    "\n",
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model \n",
    "class LogisticRegression(nn.Module): \n",
    "\tdef __init__(self, input_size, num_classes): \n",
    "\t\tsuper(LogisticRegression, self).__init__() \n",
    "\t\tself.linear = nn.Linear(input_size, num_classes) \n",
    "\n",
    "\tdef forward(self, x): \n",
    "\t\tout = self.linear(x) \n",
    "\t\treturn out \n",
    "\n",
    "model = LogisticRegression(input_size, num_classes) \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i , (images,label) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 100 == 0 :\n",
    "            print('Epoch: [%]')\n",
    "\n",
    "\n",
    "# Training the Model \n",
    "for epoch in range(num_epochs): \n",
    "\tfor i, (images, labels) in enumerate(train_loader): \n",
    "\t\timages = Variable(images.view(-1, 28 * 28)) \n",
    "\t\tlabels = Variable(labels) \n",
    "\n",
    "\t\t# Forward + Backward + Optimize \n",
    "\t\toptimizer.zero_grad() \n",
    "\t\toutputs = model(images) \n",
    "\t\tloss = criterion(outputs, labels) \n",
    "\t\tloss.backward() \n",
    "\t\toptimizer.step() \n",
    "\n",
    "\t\tif (i + 1) % 100 == 0: \n",
    "\t\t\tprint('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
    "\t\t\t\t% (epoch + 1, num_epochs, i + 1, \n",
    "\t\t\t\t\tlen(train_dataset) // batch_size, loss.data.item())) \n",
    "\n",
    "# Test the Model \n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader: \n",
    "\timages = Variable(images.view(-1, 28 * 28)) \n",
    "\toutputs = model(images) \n",
    "\t_, predicted = torch.max(outputs.data, 1) \n",
    "\ttotal += labels.size(0) \n",
    "\tcorrect += (predicted == labels).sum() \n",
    "\n",
    "print('Accuracy of the model on the 10000 test images: % d %%' % ( \n",
    "\t\t\t100 * correct / total)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296e9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
